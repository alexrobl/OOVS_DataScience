{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f989da56-3c5f-4c43-aef0-b793f1e5360c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26587453-ac99-4d8b-9fae-300e4cb22287",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# listado de ubicacion shape de Lotes de bogota con geometria de punto.\n",
    "[a.path for a in dbutils.fs.ls(\"/FileStore/tables/shp/Lotes_centroide/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd3aa730-1075-49ec-b9a5-8f8b802ffa7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel\n",
    "from sedona.spark import *\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "# configuración de spark y Sedona para datos geograficos\n",
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"Sedona App\").\\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName).\\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) .\\\n",
    "    config(\"spark.kryoserializer.buffer.max\", \"200gb\").\\\n",
    "    getOrCreate()\n",
    "\n",
    "#SedonaRegistrator.registerAll()\n",
    "SedonaContext.create(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbae4e76-f370-4d3b-a9c3-e82adee0c158",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import geopandas as gpd\n",
    "#lote = gpd.read_file(\"/dbfs/FileStore/tables/shp/Lotes_centroide/Puntos_lote.shp\")\n",
    "\n",
    "# LOTES FILTRADOS PLMB\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from sedona.utils.adapter import Adapter\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")\n",
    "#Lotes\n",
    "Lotes = ShapefileReader.readToGeometryRDD(sc, \"dbfs:/FileStore/tables/shp/Lotes_centroide/\")\n",
    "Isocrona = ShapefileReader.readToGeometryRDD(sc, \"dbfs:/FileStore/tables/shp/isocronas/\")\n",
    "Lotes_df = Adapter.toDf(Lotes, spark)\n",
    "Isocrona_df = Adapter.toDf(Isocrona, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "464c4272-7475-471e-bf11-a7cabe33cefb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Lotes.CRSTransform('epsg:4326','epsg:4326')\n",
    "Isocrona.CRSTransform('epsg:4326','epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f78af0bb-e88b-438f-a612-862fa6a307ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Isocrona.rawSpatialRDD.filter(lambda x: [x.userData.split(\"\\t\")]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b09e9dcb-cab7-4255-b94f-10ba18aef873",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "l_gdf = gpd.GeoDataFrame(\n",
    "    Lotes.rawSpatialRDD.map(lambda x: [x.geom]).sample(False, 0.0009,6).collect(),\n",
    "    columns=[\"geom\"],\n",
    "    geometry=\"geom\",\n",
    "    crs = 'epsg:4326'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "021e5e19-b94d-43fc-9b91-ce0fc3f818d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sedona.core.spatialOperator import JoinQuery\n",
    "# haciendo las particiones espaciales\n",
    "Lotes.analyze()\n",
    "Lotes.spatialPartitioning(GridType.KDBTREE, 4)\n",
    "Isocrona.spatialPartitioning(Lotes.getPartitioner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "715c8e63-40de-4518-882d-77000b601124",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sedona.core.enums import GridType\n",
    "from sedona.core.enums import IndexType\n",
    "from sedona.core.spatialOperator import JoinQuery\n",
    "\n",
    "\n",
    "build_on_spatial_partitioned_rdd = True ## Set to TRUE only if run join query\n",
    "using_index = True\n",
    "Isocrona.buildIndex(IndexType.QUADTREE, build_on_spatial_partitioned_rdd)\n",
    "\n",
    "result = JoinQuery.SpatialJoinQueryFlat(Lotes, Isocrona, using_index, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87bbc90f-bf4f-4076-b972-6b51e5465fcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valores = gpd.GeoDataFrame(\n",
    "    result.map(lambda x: [x[1].geom, *x[0].userData.split(\"\\t\"), *x[1].userData.split(\"\\t\")]).collect(),columns=[\"geom\", 'group_inde','Tiempo','layer','Linea','LOTSECT_ID','LOTMANZ_ID','LOTLOTE_ID','LOTZHF_ID','LOTZHG_ID','LOTUNIDAPH','LOTDISTRIT','LOTLSIMBOL','ESTADO_REG','FECHA_REGI','FECHA_DESD','FECHA_HAST','LOTLNUMERO','FRENTE','FONDO'],\n",
    "    geometry=\"geom\",\n",
    "    crs= \"epsg:4326\"\n",
    ")\n",
    "#.sample(False, 0.0009,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c2e1a66-77c1-4a9a-bbd1-fd17ec41e16d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "valores['Linea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cadfd0d-5d93-4151-9a76-5805c7371e60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valores[['geom','Tiempo']].sample(20000).explore('Tiempo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d46e2a7f-1f82-43cf-a37e-cc5b840fa52c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# CRUCE CON USOS E INMUEBLES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af15ea8b-d872-4738-83e4-51ff98400851",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "startpath = '/dbfs/FileStore/tables/Catastro/'\n",
    "\n",
    "# crea listados por grupo de archivos para cada año junto a un diccionario de la información disponible de catastro\n",
    "# desde el año 2006 hasta 2022\n",
    "ph = list()\n",
    "pre = list()\n",
    "uso = list()\n",
    "dict_anio = dict()\n",
    "\n",
    "for root, dirs, files in os.walk(startpath):\n",
    "    periodos = [str(a) for a in range(2006,2023)]\n",
    "    # recorre el arreglo de años   \n",
    "    if os.path.basename(root) in periodos:\n",
    "        carpeta = os.path.basename(root)\n",
    "        ph_predios = '{}/ph_{}.csv'.format(root, carpeta)\n",
    "        predios = '{}/predios_{}.csv'.format(root, carpeta)\n",
    "        usos = '{}/usos_{}.csv'.format(root, carpeta)\n",
    "        lista_interna = list()\n",
    "        for f in files:\n",
    "            if 'ph_' in f:\n",
    "                lista_interna.append(ph_predios)\n",
    "                ph.append(ph_predios)\n",
    "            elif 'predios_'in f:\n",
    "                lista_interna.append(predios)\n",
    "                pre.append(predios)\n",
    "            elif 'usos_'in f:\n",
    "                lista_interna.append(usos)\n",
    "                uso.append(usos)\n",
    "            else:\n",
    "                pass\n",
    "        dict_anio[carpeta] = lista_interna\n",
    "        del lista_interna\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29659dd8-21bf-42dc-a64d-d4b921473579",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# se definen los usos definidos y agrupados por los profesionales del equipo OOVS\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Iniciar una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"usos\").getOrCreate()\n",
    "\n",
    "hUsos={\n",
    "    'Asociar al uso principal':['AREA DE MEZANINE EN PH','DEPOSITO (LOCKERS) PH','DEPOSITO ALMACENAMIENTO PH','PARQUEO CUBIERTO NPH','PARQUEO CUBIERTO PH','PARQUEO LIBRE PH','PISCINAS EN NPH','PISCINAS EN PH'],\n",
    "    'Comercio y servicios':['BODEGA COMERCIAL NPH','BODEGA COMERCIAL PH','BODEGA ECONOMICA','BODEGA ECONOMICA(SERVITECA,ESTA.SERVIC.)','BODEGAS DE ALMACENAMIENTO NPH','BODEGAS DE ALMACENAMIENTO PH','CENTRO COMERCIAL GRANDE NPH','CENTRO COMERCIAL GRANDE PH','CENTRO COMERCIAL MEDIANO NPH','CENTRO COMERCIAL MEDIANO PH','CENTRO COMERCIAL PEQUENO NPH','CENTRO COMERCIAL PEQUENO PH','CLUBES PEQUENOS','COMERCIO PUNTUAL NPH O HASTA 3 UNID PH','COMERCIO PUNTUAL PH','CORREDOR COMERCIAL NPH O HASTA 3 UNID PH','CORREDOR COMERCIAL PH','DEPOSITOS DE ALMACENAMIENTO NPH','EDIFICIOS DE PARQUEO NPH','EDIFICIOS DE PARQUEO PH','HOTELES NPH','HOTELES PH','MOTELES, AMOBLADOS, RESIDENCIAS NPH','MOTELES, AMOBLADOS, RESIDENCIAS PH','OFICINA BODEGA Y/O INDUSTRIA PH','OFICINAS EN BODEGAS Y/O INDUSTRIAS','OFICINAS OPERATIVAS','OFICINAS OPERATIVAS(ESTACIONES SERVICIO)','OFICINAS Y CONSULTORIOS NPH','OFICINAS Y CONSULTORIOS PH','PARQUES DE DIVERSION','RESTAURANTES NPH','RESTAURANTES PH','TEATROS Y CINEMAS NPH','TEATROS Y CINEMAS PH'],\n",
    "    'Dotacional':['AULAS DE CLASE','CEMENTERIOS','CENTROS MEDICOS EN PH','CLINICAS, HOSPITALES, CENTROS MEDICOS','CLUBES MAYOR EXTENSION','COLEGIOS EN PH','COLEGIOS Y UNIVERSIDADES 1 A 3 PISOS','COLEGIOS Y UNIVERSIDADES 4 O MAS PISOS','COLISEOS','CULTO RELIGIOS EN NPH','CULTO RELIGIOSO EN PH','IGLESIA PH','IGLESIAS','INSTALACIONES MILITARES','INSTITUCIONAL PH','INSTITUCIONAL PUNTUAL','MUSEOS','OFICINAS Y CONSULTORIOS (OFICIAL) NPH','OFICINAS Y CONSULTORIOS (OFICIAL) PH','PLAZAS DE MERCADO'],\n",
    "    'Industrial':['INDUSTRIA ARTESANAL','INDUSTRIA GRANDE','INDUSTRIA GRANDE PH','INDUSTRIA MEDIANA','INDUSTRIA MEDIANA PH'],\n",
    "    'Otro':['COCHERAS, MARRANERAS, PORQUERIZAS','ENRAMADAS, COBERTIZOS, CANEYES','ESTABLOS, PESEBRERAS','GALPONES, GALLINEROS','KIOSKOS','LOTE EN PROPIEDAD HORIZONTAL','PISTA AEROPUERTO','SILOS'],\n",
    "    'Residencial':['HABITACIONAL EN PROPIEDAD HORIZONTAL','HABITACIONAL MAYOR O IGUAL A 4 PISOS NPH O 3 PISOS PH','HABITACIONAL MENOR O IGUAL A 3 PISOS NPH','HABITACIONAL MENOR O IGUAL A 3 PISOS PH']\n",
    " }\n",
    "\n",
    "def homoUso(uso_catastro:str,usos_agregados=hUsos):\n",
    "    '''\n",
    "    Toma el uso de la base de predios de catastro y lo agrega a \n",
    "    categorias mas sencillas de entender para el análisis de datos del OOVS\n",
    "\n",
    "    Args:\n",
    "        input_str (str): Cadena de texto que trae el uso para gregarlo.\n",
    "\n",
    "    Returns:\n",
    "        str: retorna el uso agragado y homologado por el equipo del observatorio\n",
    "    '''\n",
    "    for k,v in usos_agregados.items():\n",
    "        if uso_catastro in v:\n",
    "            return k\n",
    "        elif uso_catastro not in v:\n",
    "            pass\n",
    "\n",
    "# Registrar la función Python como UDF de Spark\n",
    "homoUso_udf = udf(homoUso, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3664f9e9-def4-40db-90af-d3a1d9ec4ba3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# recorre el arreglo de los archivos de uso y crea un nuevo campo con el uso agregado, luego lo guarda en un archivo nuevo.\n",
    "for u in uso:\n",
    "    path = u.replace(\"/dbfs\",\"dbfs:\")\n",
    "    uso_pdf = spark.read.format(\"csv\").option(\"header\", \"true\").load(path)\n",
    "    df = uso_pdf.withColumn(\"UsoAgregado\", homoUso_udf(uso_pdf[\"DESCRIPCION_USO\"]))\n",
    "    new_name = path.replace('.csv','_agregado.csv') #uso homologado\n",
    "    df.write.csv(new_name, header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b091482-a13b-435e-9ff8-a985de138c01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "[a.path for a in dbutils.fs.ls(\"/FileStore/tables/Catastro/2010/\")]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2687159396482680,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Procesamiento",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
