{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f9aac37-9fcb-4957-b0ca-2505e2c71cda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Preparación datos - Tablero Construcción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a58f5852-2866-4254-b644-cf02045d2910",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f642dcc-c9f4-4da5-8bb0-72977b8aca47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import unicodedata\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import jenkspy\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, cast, when, udf, struct, from_json, count, countDistinct, lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, LongType\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "from sedona.spark import *\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from sedona.utils.adapter import Adapter\n",
    "from sedona.core.enums import IndexType\n",
    "from sedona.core.enums import GridType\n",
    "from sedona.core.spatialOperator import JoinQuery\n",
    "\n",
    "from sedona.core.SpatialRDD import PointRDD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67043975-f892-49cf-ae23-a49b0f01b83a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Parametrización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c692b488-095e-4ef5-b208-dca8dae3fc61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "num_partitions = 4\n",
    "url = \"https://catalogopmb.catastrobogota.gov.co/PMBWeb/web/api\"\n",
    "startpath = '/dbfs/FileStore/tables/Catastro/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8afe834f-3f02-4f62-b84c-1d3565d6a53a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# configuración de spark y Sedona para datos geograficos\n",
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"Sedona App\").\\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName).\\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) .\\\n",
    "    config(\"spark.kryoserializer.buffer.max\", \"200gb\").\\\n",
    "    getOrCreate()\n",
    "\n",
    "SedonaContext.create(spark)\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aee7356-20bc-4563-81c7-abbb6faa4361",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usos_licencias_homologados = {\n",
    "    'Residencial':['Vivienda'],\n",
    "    'Comercio y servicios':['Comercio','Oficinas','Servicios'],\n",
    "    'Industrial':['Industria'],\n",
    "    'Otros':['Dotacionales','Institucional','Estacionamientos / Parqueaderos','Otros','Sin informacion','Sin Información','Recreativos']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1344b6b3-b214-449c-a29f-2f293be41958",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "modalidades_homologadas = {\n",
    "    'Obra nueva':['1.Obra Nueva','1.Obra nueva'],\n",
    "    'Ampliación':['2.Ampliación'],\n",
    "    'Modificación':['Modificación'],\n",
    "    'Demolición':['Demolición Total', 'Demolición Parcial', 'Demolición'],\n",
    "    'Reforzamiento Estructural':['Reforzamiento Estructural'],\n",
    "    'Restauración':['Restauración'],\n",
    "    'Cerramiento':['Cerramiento'],\n",
    "    'Adecuación':['Adecuación'],\n",
    "    'Subdivisión':['Subdivisión urbana', 'Subdivisión rural'],\n",
    "    'Propiedad Horizontal':['Propiedad Horizontal'],\n",
    "    'Sin Modalidad':['Sin Modalidad', 'Ninguna', 'Sin Información', 'No Aplica Modalidad'],\n",
    "    'Culminación de Obras':['Culminación de Obras'],\n",
    "    'Reconocimiento':['Reconocimiento'],\n",
    "    'Desarrollo':['Desarrollo','Desarrollo por etapas'],\n",
    "    'Otras':['Restitución','Reloteo', 'Área Bruta Urbanismo', 'Área Útil Urbanismo', 'Saneamiento', 'Reconstrucción'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb28abbd-6511-4654-92b4-0da67178e4e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ac73dd-41f5-4a1b-be0a-651325c3cada",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def remove_words_from_string(input_str, words_to_remove):\n",
    "    for word in words_to_remove:\n",
    "        input_str = input_str.replace(word, \"\")\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56d8e192-2a2a-4cd5-8bb3-601f126c66bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_ph_address(s):\n",
    "    s = re.sub(r'\\b(AP|GJ|IN|LT) \\d+\\b', '', s).strip()\n",
    "    if 'SUR' in s:\n",
    "        s = re.sub(r'\\bSUR\\b', '', s).strip() + ' S'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc68737d-5152-430c-b406-d1169062cc6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"estado\", StringType()), StructField(\"yinput\", DoubleType()), StructField(\"lotcodigo\", StringType()),\n",
    "                    StructField(\"latitude\", StringType()), StructField(\"diraprox\", StringType()), StructField(\"mancodigo\", StringType()),\n",
    "                    StructField(\"cpocodigo\", StringType()), StructField(\"xinput\", DoubleType()), StructField(\"codloc\", StringType()),\n",
    "                    StructField(\"dirtrad\", StringType()), StructField(\"nomupz\", StringType()), StructField(\"localidad\", StringType()),\n",
    "                    StructField(\"dirinput\", StringType()), StructField(\"codupz\", StringType()), StructField(\"nomseccat\", StringType()),\n",
    "                    StructField(\"tipo_direccion\", StringType()), StructField(\"codseccat\", StringType()), StructField(\"longitude\", StringType()),\n",
    "                ])\n",
    "def georeferenciar(input_str:str):\n",
    "    \"\"\"\n",
    "    Realiza la georreferenciación de una cadena de entrada utilizando una API de geocodificación.\n",
    "\n",
    "    Args:\n",
    "        input_str (str): La cadena a georreferenciar.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario que contiene los datos de georreferenciación si la operación fue exitosa.\n",
    "              En caso contrario, devuelve un diccionario que indica un estado de falla o un estado de error.\n",
    "\n",
    "    \"\"\"\n",
    "    schema = StructType([StructField(\"estado\", StringType()), StructField(\"yinput\", DoubleType()), StructField(\"lotcodigo\", StringType()),\n",
    "                    StructField(\"latitude\", StringType()), StructField(\"diraprox\", StringType()), StructField(\"mancodigo\", StringType()),\n",
    "                    StructField(\"cpocodigo\", StringType()), StructField(\"xinput\", DoubleType()), StructField(\"codloc\", StringType()),\n",
    "                    StructField(\"dirtrad\", StringType()), StructField(\"nomupz\", StringType()), StructField(\"localidad\", StringType()),\n",
    "                    StructField(\"dirinput\", StringType()), StructField(\"codupz\", StringType()), StructField(\"nomseccat\", StringType()),\n",
    "                    StructField(\"tipo_direccion\", StringType()), StructField(\"codseccat\", StringType()), StructField(\"longitude\", StringType()),\n",
    "                ])\n",
    "\n",
    "    input_str = '' if input_str is None else input_str\n",
    "\n",
    "    direc = unicodedata.normalize(\"NFKD\", input_str).encode(\"ascii\",\"ignore\").decode(\"ascii\").lower()\n",
    "\n",
    "    val = [True for t in direc.replace('.',' ').replace(\"  \",\" \").split() if t in ['via','km','chia','cota','tocancipa','tenjo','madrid','tabio,','cajica,','mosquera','zipaquira']]\n",
    "    \n",
    "    if sum(val)>=1:\n",
    "        result = {'estado': 'outside_bogota','yinput':0,'lotcodigo':'','latitude':'','diraprox':'','mancodigo':'','cpocodigo':'','xinput':0,'codloc':'','dirtrad':'','nomupz':'','localidad':'','dirinput':'','codupz':'','nomseccat':'','tipo_direccion':'','codseccat':'','longitude':''}\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            words_to_remove = [\"costado occ.\", \"esquina\"]\n",
    "            direc = remove_words_from_string(direc, words_to_remove)\n",
    "            direc = clean_ph_address(direc)\n",
    "\n",
    "            pattern = r'av\\.?(?: de la)? esp\\.?|\\bavenida la esperanza\\b|\\besperanza\\b'\n",
    "            replacement_str = \"AC 24\"\n",
    "            output_str = re.sub(pattern, replacement_str, direc)\n",
    "\n",
    "            pattern = r'av\\.?(?: de las)? ame\\.?|\\bavenida de las americas\\b|\\bamericas\\b'\n",
    "            replacement_str = \"AC 9\"\n",
    "            output_str = re.sub(pattern, replacement_str, output_str)\n",
    "\n",
    "            pattern = r'(autop\\.?(\\s)?norte|autonorte|au\\.?(\\s)?norte|aut\\.?(\\s)?norte)'\n",
    "            replacement_str = \"AK 45\"\n",
    "            output_str = re.sub(pattern, replacement_str, output_str)\n",
    "\n",
    "            pattern = r'av\\.?(?: de las)?(?: c\\.?)?\\s*(?:ciudad\\s*)?cali|avenida\\s*cali'\n",
    "            replacement_str = \"AK 86\"\n",
    "            output_str = re.sub(pattern, replacement_str, output_str)\n",
    "\n",
    "            pattern = r'av. nqs|\\bnqs\\b'\n",
    "            replacement_str = \"AK 30\"\n",
    "            output_str = re.sub(pattern, replacement_str, output_str)\n",
    "\n",
    "            pattern = r'av. suba|\\bsuba\\b|tr. suba'\n",
    "            replacement_str = \"AK 69\"\n",
    "            output_str = re.sub(pattern, replacement_str, output_str)\n",
    "\n",
    "            output_str = output_str.replace('cl. av.', 'AC')\n",
    "            output_str = output_str.replace('av. cl.', 'AC')\n",
    "            output_str = output_str.replace('av. cr.', 'AK')\n",
    "\n",
    "            con = False\n",
    "\n",
    "            output_str = output_str.replace('con','#')\n",
    "            output_str = output_str.replace('paralela','#')\n",
    "\n",
    "            parts = output_str.split(\"#\")\n",
    "\n",
    "            if len(parts) > 1:\n",
    "                if '-' not in parts[1]:\n",
    "                    parts[1] = re.sub(r'[a-zA-Z.]', '', parts[1])\n",
    "                    output_str = \"#\".join(parts)\n",
    "\n",
    "            \n",
    "\n",
    "            pattern = r'(\\d+)\\D+(\\w+)'\n",
    "            output_str = re.sub(pattern, lambda x: x.group(1) + ' # ' + x.group(2), output_str)\n",
    "\n",
    "            if '-' not in output_str:\n",
    "                output_str = output_str + ' - 01'\n",
    "\n",
    "\n",
    "            parts = output_str.split(\"#\")\n",
    "\n",
    "            if parts[0].strip() == 'AK 30' and (int(parts[1].split('-')[0].strip())>100):\n",
    "                parts[0] = 'AK 9'\n",
    "                output_str = \"#\".join(parts)\n",
    "\n",
    "            output_str = output_str.replace(\"AK 69\",'Av Suba')\n",
    "\n",
    "            print(output_str)\n",
    "\n",
    "            params = {\n",
    "                'cmd': 'geocodificar',\n",
    "                'apikey': '1c025f92-4520-49c1-90a7-a24b3d9d374c',\n",
    "                'query': output_str\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, params=params)\n",
    "            res = response.json()\n",
    "            success = res['response']['success']\n",
    "            if success:\n",
    "                result = res['response']['data']\n",
    "                return result\n",
    "            else:\n",
    "                result = {'estado': 'failed','yinput':0,'lotcodigo':'','latitude':'','diraprox':'','mancodigo':'','cpocodigo':'','xinput':0,'codloc':'','dirtrad':'','nomupz':'','localidad':'','dirinput':'','codupz':'','nomseccat':'','tipo_direccion':'','codseccat':'','longitude':''}\n",
    "                return result\n",
    "        except:\n",
    "            result = {'estado': 'error_ws','yinput':0,'lotcodigo':'','latitude':'','diraprox':'','mancodigo':'','cpocodigo':'','xinput':0,'codloc':'','dirtrad':'','nomupz':'','localidad':'','dirinput':'','codupz':'','nomseccat':'','tipo_direccion':'','codseccat':'','longitude':''}\n",
    "            \n",
    "            return result\n",
    "        \n",
    "georeferenciar_udf = udf(georeferenciar, returnType=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f8b3c48-58b3-44b6-a8ee-ff6828935694",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_point_udf = udf(lambda x,y: Point(x,y).wkt, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37925cbd-debf-4fc0-bb8d-e29dad8b75a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def homologar_uso_licencia(uso:str,usos_agregados=usos_licencias_homologados):\n",
    "    '''\n",
    "    Toma el uso de la base de predios de catastro y lo agrega a \n",
    "    categorias mas sencillas de entender para el análisis de datos del OOVS\n",
    "\n",
    "    Args:\n",
    "        input_str (str): Cadena de texto que trae el uso para gregarlo.\n",
    "\n",
    "    Returns:\n",
    "        str: retorna el uso agragado y homologado por el equipo del observatorio\n",
    "    '''\n",
    "    for k,v in usos_agregados.items():\n",
    "        if uso in v:\n",
    "            return k\n",
    "        elif uso not in v:\n",
    "            pass\n",
    "homoUsoLicencia_udf = udf(homologar_uso_licencia, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cd7a7c6-c08f-406d-8a39-3968a8e31018",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def homologar_modalidad(modalidad_licencia:str,modalidades_agregados=modalidades_homologadas):\n",
    "    '''\n",
    "    Toma el uso de la base de predios de catastro y lo agrega a \n",
    "    categorias mas sencillas de entender para el análisis de datos del OOVS\n",
    "\n",
    "    Args:\n",
    "        input_str (str): Cadena de texto que trae el uso para gregarlo.\n",
    "\n",
    "    Returns:\n",
    "        str: retorna el uso agragado y homologado por el equipo del observatorio\n",
    "    '''\n",
    "    for k,v in modalidades_agregados.items():\n",
    "        if modalidad_licencia in v:\n",
    "            return k\n",
    "        elif modalidad_licencia not in v:\n",
    "            pass\n",
    "homoModalidad_udf = udf(homologar_modalidad, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d496a477-c72a-40fc-a3af-3ed7e8e9e8b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_coordinates(x, y):\n",
    "    if x is not None and y is not None and x != 'NULL' and y!='NULL' and x != 0.0 and y!=0.0 and isinstance(x, (float)) and isinstance(y, (float)):\n",
    "        source_crs = pyproj.CRS(\"ESRI:102233\")\n",
    "        target_crs = pyproj.CRS(\"EPSG:4326\")\n",
    "        transformer = pyproj.Transformer.from_crs(source_crs, target_crs, always_xy=True)\n",
    "        new_x, new_y = transformer.transform(x, y)\n",
    "        return new_x, new_y\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "coordinate_udf = udf(transform_coordinates, StructType([StructField(\"wgs84_lng\", DoubleType(), False),\n",
    "                                                        StructField(\"wgs84_lat\", DoubleType(), False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bc5358b-0059-45cc-bff3-8fa7e30c71f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_year_from_path(path, paths_dict):\n",
    "    # Iterate over the dictionary to find the year for the given path\n",
    "    for year, paths in paths_dict.items():\n",
    "        if path in paths:\n",
    "            return year\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b176779-d93d-4678-80aa-5886cbcb5c4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Cargue de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30215f9e-ee85-4478-834d-051646b0d4bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Licencias (SDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab09003-1609-49b7-825f-8c5c4997b51a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definimos la ubicación del archivo que queremos leer.\n",
    "file_location = \"/FileStore/tables/SDP/sdp_licencias_2008_2023.csv\"\n",
    "\n",
    "# Especificamos el tipo de archivo. En este caso, es un archivo CSV.\n",
    "file_type = \"csv\"\n",
    "\n",
    "# Definimos algunas opciones para la lectura del archivo:\n",
    "# - 'infer_schema': Si es \"true\", Spark intentará inferir automáticamente el esquema (tipos de datos) de las columnas.\n",
    "# - 'first_row_is_header': Si es \"true\", Spark tratará la primera fila del archivo CSV como encabezados (nombres de columnas).\n",
    "# - 'delimiter': Especifica el delimitador utilizado en el archivo CSV. En este caso, es una coma.\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# Usamos el método 'read' de Spark para leer el archivo CSV con las opciones especificadas.\n",
    "# El resultado es un DataFrame llamado 'df_licencias' que contiene los datos del archivo CSV.\n",
    "df_licencias = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42333904-6c94-4aef-b6fb-6cbb57109b60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Georeferenciación de licencias SDP a partir de dirección catastral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a07843f-73b0-4913-ab6f-7b529786ac6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_licencias = df_licencias.withColumn('geocode_result', struct(georeferenciar_udf(col('Dirección')).alias('geocoding')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c385f11-c4fc-40dc-86f2-50fcb42bee8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_licencias = df_licencias.withColumn('estado', col('geocode_result.geocoding.estado'))\n",
    "# df_licencias = df_licencias.withColumn('tipo_direccion', col('geocode_result.geocoding.tipo_direccion'))\n",
    "# df_licencias = df_licencias.withColumn('diraprox', col('geocode_result.geocoding.diraprox'))\n",
    "# df_licencias = df_licencias.withColumn('lat', col('geocode_result.geocoding.yinput'))\n",
    "# df_licencias = df_licencias.withColumn('lng', col('geocode_result.geocoding.xinput'))\n",
    "# df_licencias = df_licencias.withColumn('lotcodigo', col('geocode_result.geocoding.lotcodigo'))\n",
    "# df_licencias = df_licencias.withColumn('eq_lot_georef', col('lotcodigo').cast(LongType()) == col('Código lote').cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a9fd6d3-14dd-4512-806c-5746d73ebd94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_licencias = df_licencias.drop('geocode_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d686bf97-84b7-4683-acbc-052cc323aaa6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_licencias.write.csv('/FileStore/tables/SDP/sdp_licencias_2008_2023_georef.csv', header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "349f1ea5-c93a-445a-80ed-99cec16afea3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_licencias = spark.read.csv('/FileStore/tables/SDP/sdp_licencias_2008_2023_georef.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d937ddd-d8e2-4693-b0f6-5cc535e13f3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agregamos una nueva columna \"new_coords\" al DataFrame df_licencias.\n",
    "# Esta columna se genera utilizando la función definida por el usuario 'coordinate_udf',\n",
    "# que toma como entrada las columnas \"Longitud\" y \"Latitud\".\n",
    "df_licencias = df_licencias.withColumn(\"new_coords\", coordinate_udf(\"Longitud\", \"Latitud\"))\n",
    "\n",
    "# Seleccionamos todas las columnas del DataFrame original, y adicionalmente extraemos\n",
    "# los campos 'wgs84_lng' y 'wgs84_lat' de la columna \"new_coords\".\n",
    "# Posteriormente, eliminamos la columna \"new_coords\" para mantener solo los campos extraídos.\n",
    "df_licencias = df_licencias.select(\"*\", \"new_coords.wgs84_lng\", \"new_coords.wgs84_lat\").drop(\"new_coords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6ffd2fb-8e26-4e4b-be36-074e3311cdf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Actualizamos el DataFrame df_licencias agregando una nueva columna \"def_lng\".\n",
    "# Si \"wgs84_lng\" no es nulo y es diferente de 0, se usa el valor de \"wgs84_lng\".\n",
    "# En caso contrario, se utiliza el valor de la columna \"lng\".\n",
    "df_licencias = df_licencias.withColumn(\n",
    "    \"def_lng\",\n",
    "    when(\n",
    "        (col(\"wgs84_lng\").isNotNull()) & \n",
    "        (col(\"wgs84_lng\") != 0), \n",
    "        col(\"wgs84_lng\")\n",
    "    ).otherwise(col(\"lng\"))\n",
    ")\n",
    "\n",
    "# Similar al proceso anterior, actualizamos el DataFrame df_licencias agregando una nueva columna \"def_lat\".\n",
    "# Si \"wgs84_lat\" no es nulo y es diferente de 0, se usa el valor de \"wgs84_lat\".\n",
    "# En caso contrario, se utiliza el valor de la columna \"lat\".\n",
    "df_licencias = df_licencias.withColumn(\n",
    "    \"def_lat\",\n",
    "    when(\n",
    "        (col(\"wgs84_lat\").isNotNull()) & \n",
    "        (col(\"wgs84_lat\") != 0), \n",
    "        col(\"wgs84_lat\")\n",
    "    ).otherwise(col(\"lat\"))\n",
    ")\n",
    "\n",
    "# Definimos una lista de columnas que queremos eliminar del DataFrame.\n",
    "columns_to_drop = [\"Latitud\", \"Longitud\", \"wgs84_lng\", \"wgs84_lat\", \"lat\", \"lng\", \"eq_lot_georef\"]\n",
    "\n",
    "# Eliminamos las columnas especificadas en la lista 'columns_to_drop' del DataFrame df_licencias.\n",
    "df_licencias = df_licencias.drop(*columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7054f211-765b-4ed6-89e9-c9021b1da2e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Actualizamos el DataFrame df_licencias agregando una nueva columna \"ModalidadAgregada\".\n",
    "# Esta columna se genera utilizando la función definida por el usuario 'homoModalidad_udf',\n",
    "# que toma como entrada la columna \"Modalidad\" del DataFrame.\n",
    "df_licencias = df_licencias.withColumn(\"ModalidadAgregada\", homoModalidad_udf(df_licencias[\"Modalidad\"]))\n",
    "\n",
    "# Eliminamos la columna \"Modalidad\" del DataFrame df_licencias ya que ha sido reemplazada por \"ModalidadAgregada\".\n",
    "df_licencias = df_licencias.drop(\"Modalidad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c9ef1d-251c-4ee8-8f59-eff42f6d96f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Actualizamos el DataFrame df_licencias agregando una nueva columna \"UsoAgregado\".\n",
    "# Esta columna se genera utilizando la función definida por el usuario 'homoUsoLicencia_udf',\n",
    "# que toma como entrada la columna \"Uso\" del DataFrame.\n",
    "df_licencias = df_licencias.withColumn(\"UsoAgregado\", homoUsoLicencia_udf(df_licencias[\"Uso\"]))\n",
    "\n",
    "# Eliminamos la columna \"Modalidad\" del DataFrame df_licencias ya que ha sido reemplazada por \"ModalidadAgregada\".\n",
    "df_licencias = df_licencias.drop(\"Uso\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c94951e9-182d-4bb1-ac03-ad3d394f3aa7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definimos una lista de tipos de trámites que queremos filtrar en el DataFrame.\n",
    "tipo_tramite = ['Licencia de Construcción','Reconocimiento de la existencia de una construcción','Licencia de Urbanización','Licencia de Urbanismo y construcción','Propiedad Horizontal','Licencia de Subdivisión','Revalidación licencia de construcción','Autorización para el movimiento de tierras','Sin informacion','Modificación','Ajuste de cotas de áreas','Copia Certificada de planos','Sin Tipo de Trámite','Inicial','Modificación de planos urbanísticos']\n",
    "tipo_tramite = ['Licencia de Construcción']\n",
    "\n",
    "# Filtramos el DataFrame df_licencias para mantener solo las filas donde 'Tipo Trámite' esté en la lista tipo_tramite.\n",
    "df_licencias = df_licencias.filter(col('Tipo Trámite').isin(tipo_tramite))\n",
    "\n",
    "objeto_tramite = ['Inicial','Modificación']\n",
    "\n",
    "df_licencias = df_licencias.filter(col('Objeto trámite').isin(objeto_tramite))\n",
    "\n",
    "# Definimos una lista de modalidades que queremos filtrar en el DataFrame.\n",
    "modalidades = ['Obra nueva','Ampliación','Modificación','Demolición','Reforzamiento Estructural','Restauración','Cerramiento','Adecuación','Subdivisión','Propiedad Horizontal','Sin Modalidad','Culminación de Obras','Reconocimiento','Desararollo','Otras']\n",
    "modalidades = ['Obra nueva']\n",
    "\n",
    "# Filtramos el DataFrame df_licencias para mantener solo las filas donde 'ModalidadAgregada' esté en la lista modalidades.\n",
    "df_licencias = df_licencias.filter(col('ModalidadAgregada').isin(modalidades))\n",
    "\n",
    "# Definimos una lista de decisiones que queremos filtrar en el DataFrame.\n",
    "#decidiones = ['Aprobado', 'Desistido','Aclarado','Prorrogado','Negado','Recurso Confirmado', 'Recurso Rechazado', 'Recurso Aclarado', 'Renuncia de Licencia', 'Revocado', 'Archivado']\n",
    "#decidiones = ['Aprobado', 'Desistido','Renuncia de Licencia']\n",
    "\n",
    "# Filtramos el DataFrame df_licencias para mantener solo las filas donde 'Tipo de decisión' esté en la lista decidiones.\n",
    "#df_licencias = df_licencias.filter(col('Tipo de decisión').isin(decidiones))\n",
    "\n",
    "# Filtramos el DataFrame df_licencias para mantener solo las filas donde 'Conteo licencias' sea mayor a 0.\n",
    "df_licencias = df_licencias.filter(col('Conteo licencias') > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da379dcf-dc9a-4180-b38d-9500855e10b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupamos el DataFrame 'predios_agregados_df' por las columnas 'LOTLOTE_ID' y 'año_vigencia'.\n",
    "# Luego, aplicamos varias funciones de agregación:\n",
    "# - Sumamos los valores de la columna 'AREA_TERRENO'.\n",
    "# - Sumamos los valores de la columna 'AREA_CONSTRUIDA'.\n",
    "# - Sumamos los valores de la columna 'VALOR_AVALUO'.\n",
    "# - Contamos el número de valores en la columna 'CHIP'.\n",
    "# El resultado es un DataFrame que tiene una columna para cada función de agregación aplicada.\n",
    "conteo_licencias = df_licencias.groupBy([\"Código lote\",\"Año de ejecutoría\"]).agg({\"Área\":\"sum\", \"Unidades\":\"sum\", \"Matrícula Inmobiliaria\":\"count\", \"CHIP\":\"count\"}).fillna(0)\n",
    "## Matrícula Inmobiliaria, CHIP, Unidades\tÁrea\n",
    "# Renombramos las columnas del DataFrame 'conteo_predios' para que tengan nombres más descriptivos y fáciles de entender.\n",
    "# - \"count(CHIP)\" se renombra a \"NumPredios\".\n",
    "# - \"sum(VALOR_AVALUO)\" se renombra a \"ValorAvaluo\".\n",
    "# - \"sum(AREA_CONSTRUIDA)\" se renombra a \"AC\".\n",
    "# - \"sum(AREA_TERRENO)\" se renombra a \"AT\".\n",
    "conteo_licencias = conteo_licencias.withColumnRenamed(\"count(CHIP)\",\"NumCHIP\") \\\n",
    "    .withColumnRenamed(\"sum(Área)\",\"Area\") \\\n",
    "    .withColumnRenamed(\"sum(Unidades)\",\"Unidades\") \\\n",
    "    .withColumnRenamed(\"count(Matrícula Inmobiliaria)\",\"Matriculas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "095e5132-7772-438c-8938-bc51a0aafd31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_licencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc583ed-7b4b-4874-a04d-c3d58c85a35b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupamos el DataFrame df_licencias por las columnas \"Código lote\" y \"Año de ejecutoría\".\n",
    "# Luego, pivotamos el DataFrame usando la columna \"ModalidadAgregada\" para transformar sus valores únicos en columnas individuales.\n",
    "# Posteriormente, contamos las ocurrencias de cada combinación de \"Código lote\", \"Año de ejecutoría\" y \"ModalidadAgregada\".\n",
    "# Finalmente, reemplazamos cualquier valor nulo con 0 usando fillna(0).\n",
    "conteo_modalidades = (df_licencias.groupBy([\"Código lote\",\"Año de ejecutoría\"]).pivot(\"ModalidadAgregada\").count()).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad7904d-953d-44e7-a6a4-9039b4bbedb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupamos el DataFrame df_licencias por las columnas \"Código lote\" y \"Año de ejecutoría\".\n",
    "# Luego, pivotamos el DataFrame usando la columna \"ModalidadAgregada\" para transformar sus valores únicos en columnas individuales.\n",
    "# Posteriormente, contamos las ocurrencias de cada combinación de \"Código lote\", \"Año de ejecutoría\" y \"ModalidadAgregada\".\n",
    "# Finalmente, reemplazamos cualquier valor nulo con 0 usando fillna(0).\n",
    "conteo_usos_licencias = (df_licencias.groupBy([\"Código lote\",\"Año de ejecutoría\"]).pivot(\"UsoAgregado\").count()).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c717ff-1fa3-4945-9079-51fc55713d81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(conteo_usos_licencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a561c29-9e25-4487-866d-c94ade902ad4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convertimos el DataFrame de Spark (df_licencias) a un DataFrame de Pandas (df_licencias_pd).\n",
    "df_licencias_pd = df_licencias.toPandas()\n",
    "\n",
    "# Filtramos el DataFrame de Pandas para mantener solo las filas donde 'def_lat' no es nulo.\n",
    "df_licencias_pd = df_licencias_pd[df_licencias_pd['def_lat'].notnull()]\n",
    "\n",
    "# Filtramos el DataFrame de Pandas para mantener solo las filas donde 'def_lng' no es nulo.\n",
    "df_licencias_pd = df_licencias_pd[df_licencias_pd['def_lng'].notnull()]\n",
    "\n",
    "# Creamos una nueva columna 'geometry' en el DataFrame de Pandas.\n",
    "# Esta columna contiene objetos Point (puntos geográficos) creados a partir de las columnas 'def_lng' y 'def_lat'.\n",
    "df_licencias_pd['geometry'] = df_licencias_pd.apply(lambda row: Point(row['def_lng'], row['def_lat']), axis=1)\n",
    "\n",
    "# Convertimos el DataFrame de Pandas (df_licencias_pd) a un GeoDataFrame (licencias_gdf) usando geopandas.\n",
    "# Especificamos la columna 'geometry' como la columna que contiene las geometrías y definimos el sistema de referencia de coordenadas (CRS) como \"EPSG:4326\".\n",
    "licencias_gdf = gpd.GeoDataFrame(df_licencias_pd, geometry='geometry', crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99eea677-b2b1-4387-8ea1-903e32fd18f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convertimos el DataFrame de Spark (isocrona_df) a un DataFrame de Pandas (isocronas_pd).\n",
    "isocrona_df = isocrona_df.withColumn(\"geometry\", col(\"geometry\").cast(\"string\"))\n",
    "isocronas_pd = isocrona_df.toPandas()\n",
    "isocronas_pd['geometry'] = isocronas_pd['geometry'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8fee477-4fd3-44ce-b327-43efff8ccf81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convertimos el DataFrame de Pandas (isocronas_pd) a un GeoDataFrame (isocronas_gdf) usando geopandas.\n",
    "# Especificamos la columna 'geometry' como la columna que contiene las geometrías y definimos el sistema de referencia de coordenadas (CRS) como \"EPSG:4326\".\n",
    "isocronas_gdf = gpd.GeoDataFrame(isocronas_pd, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Realizamos una operación de join espacial entre los GeoDataFrames licencias_gdf e isocronas_gdf.\n",
    "# El join se realiza con base en la relación espacial \"within\", es decir, se unen las filas de licencias_gdf que están dentro de las geometrías de isocronas_gdf.\n",
    "# El resultado es un nuevo GeoDataFrame (licencias_gdf_iso) que contiene solo las licencias que están dentro de las isócronas.\n",
    "licencias_gdf_iso = gpd.sjoin(licencias_gdf, isocronas_gdf, how=\"inner\", op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "248f060f-7463-41ef-93cd-b3d8a0891085",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "licencias_gdf_iso[['geometry','Tiempo']].sample(5000).explore('Tiempo', tiles='CartoDB positron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca3b56d-40df-4d2f-b158-42422f3ec70b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "campos_licencias = ['Código lote','Año de ejecutoría','Localidad','UPZ','Tiempo','layer','Linea','Tipo de decisión','def_lng','def_lat']\n",
    "licencias_gdf = pd.DataFrame(licencias_gdf_iso)[campos_licencias].drop_duplicates()\n",
    "conteo_licencias_df = conteo_licencias.toPandas().drop_duplicates()\n",
    "conteo_modalidades_df = conteo_modalidades.toPandas().drop_duplicates()\n",
    "conteo_usos_licencias_df = conteo_usos_licencias.toPandas().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73b732f2-b568-4676-be65-6948de5a1e00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Realizamos una operación de unión (merge) entre el GeoDataFrame licencias_gdf_iso y el DataFrame conteo_modalidades.\n",
    "# La unión se basa en las columnas 'Código lote' y 'Año de ejecutoría'.\n",
    "# Utilizamos un join de tipo \"left\", lo que significa que se conservarán todas las filas del GeoDataFrame licencias_gdf_iso y se agregarán las columnas correspondientes del DataFrame conteo_modalidades.\n",
    "# Si no hay coincidencia para una fila en particular de licencias_gdf_iso en conteo_modalidades, los valores de las columnas agregadas serán NaN.\n",
    "union_licencias_df =  pd.merge(left=licencias_gdf, right=conteo_licencias_df, on=['Código lote','Año de ejecutoría'], how=\"left\")\n",
    "#union_licencias_df =  pd.merge(left=union_licencias_df, right=conteo_modalidades_df, on=['Código lote','Año de ejecutoría'], how=\"left\")\n",
    "union_licencias_df =  pd.merge(left=union_licencias_df, right=conteo_usos_licencias_df, on=['Código lote','Año de ejecutoría'], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5612bc7f-6f88-4d22-ada7-948aa065ed08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "union_licencias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "158f0385-5b26-4252-8c8b-6582397eb5d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#union_licencias_df.columns = ['CodigoLote','AnioDeEjecutoria','Localidad','UPZ','Tiempo','Estacion','Linea','TipoDeDecision','DefLng','DefLat','NumCHIP','Area','Unidades','Matriculas','Adecuacion','Ampliacion','Cerramiento','CulminacionDeObras','Demolicion','Modificacion','ObraNueva','Otras','PropiedadHorizontal','Reconocimiento','ReforzamientoEstructural','Restauración','SinModalidad','Subdivisión']\n",
    "union_licencias_df.columns = ['CodigoLote','AnioDeEjecutoria','Localidad','UPZ','Tiempo','Estacion','Linea','TipoDeDecision','DefLng','DefLat','NumCHIP','Area','Unidades','Matriculas','ComercioYServicios','Industrial','Otros','Residencial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9810e50f-15b6-4d42-82d0-c10d6f835505",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convertir el DataFrame de Pandas a un DataFrame de PySpark\n",
    "union_licencias_spark_df = spark.createDataFrame(union_licencias_df)\n",
    "\n",
    "# Escribir el DataFrame de PySpark a un archivo CSV\n",
    "union_licencias_spark_df.write.csv('/FileStore/tables/SDP/union_licencias_2008_2023.csv', header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b5d3120-4f5e-4dd5-a5e5-ebbaa8e72354",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "union_licencias_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "982ca001-6943-485f-a5c5-d36162eeef35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "union_licencias_spark_df.createOrReplaceTempView(\"union_sdp_spark_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a04d607-7d78-4475-b089-54d90c093e06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE lotes_licencias_sdp AS (\n",
    "  Select \n",
    "  *, cast(AnioDeEjecutoria as float) as AnioVigencia\n",
    "  from union_sdp_spark_df where CodigoLote is not null);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed0f500e-8a43-4010-aa84-3a49fe0a92f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "243c35ce-d3f9-4dbc-b443-09d24c34e5df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4485955173114332,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Preparación datos Tableros - SDP",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
